{"cells":[{"cell_type":"markdown","metadata":{"hideCode":false,"hidePrompt":false,"id":"2XnpJ3xvECv0"},"source":["# DIT821 Software Engineering for AI systems\n","\n","DIT821 labs are derived from excercises from Coursera Machine Learning course.\n","\n","<div class=\"alert alert-block alert-warning\">\n","You are supposed to solve them yourself and submit the solutions. Further, you will be asked individually to explan the labs, in particuar the parts that you have written. The labs will be approved upon sucssesful correct submission and discussion.\n","</div>\n","\n","* Name, e-mail:\n","* Cynthia Tarwireyi, gustarwfa@student.gu.se\n","* Akuen Akoi Deng, gusdengak@student.gu.se:\n","* Kanokwan Haesatith, gushaeka@student.gu.se\n","* Nazli Moghaddam, gusmogna@student.gu.se\n"]},{"cell_type":"markdown","metadata":{"hideCode":false,"hidePrompt":false,"id":"twM-0UC8ECv6"},"source":["# Programming Exercise 10: Data Management\n","\n","In this lab exercise, you will check the consistency of annotations for a selected set of images. You are provided with 10 images, and for each image there are a number of different judgements (a single judgement is one persons opinion about what the annotation should look like).  \n","\n","For each image you have a corresponding .json file that contains all of the judgements for said image. The top-level key-value pairs of the .json file correspond to judgement_number - judgement. In turn, each judgement corresponds to a list of objects, where each object contains a number of different keys that inform you about the object-class, position of the extreme points (top, right, left, bottom) and so on.\n","\n","\n","You will need the following libraries<br><br>\n","- **scipy**: For advanced mathematical routines <br>\n","- **numpy**: For N-dimensional array manipulation <br>\n","- **matplotlib**: For 2D plotting <br>\n","- **JSON**: For processing JSON file <br>\n","\n","\n","## Files included in this exercise:\n","\n","- **Annotation_consistency**\n","    - images (in jpg format)\n","    - jugements (also annotations in json format)\n","\n","## Where to get help:\n","\n","- **Working with pillow and matplotlib**:\n","    - images (imread,imshow): <https://matplotlib.org/tutorials/introductory/images.html>\n","    - patches.Rectangle: <https://matplotlib.org/3.3.0/api/_as_gen/matplotlib.patches.Rectangle.html>\n","    - pillow:<https://pillow.readthedocs.io/en/stable/reference/Image.html>\n","    \n","- **Working json**:\n","    - Read json file: <https://realpython.com/python-json/#serializing-json>\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"hideCode":false,"hidePrompt":false,"id":"_9RdpuvTECv7"},"outputs":[],"source":["# Manipulating directory paths\n","import os\n","\n","# Manipulating json files\n","import json\n","\n","# Plotting library\n","import matplotlib.pyplot as plt\n","\n","# Plotting  and manipulating image, bounding box\n","from matplotlib import image\n","import matplotlib.patches as patches\n","import matplotlib.cm as mpcm\n","import numpy as np\n","# tells matplotlib to embed plots within the notebook\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"hideCode":false,"hidePrompt":false,"id":"eQ5_waSSECv9"},"source":["\n","## Submission\n","For this programming exercise you are required to check the consistency of annotations. The following is a breakdown of how each part of this exercise.  \n","- *Step 1: Draw all boxes from one single annotator onto one image*<br>\n","- *Step 2: Draw all boxes avalibale for the same image onto the image*<br>\n","- *Step 3: Pick two boxes corresponding to the same object and draw them together c*<br>\n","- *Step 4: Compute the IOU between them*<br>"]},{"cell_type":"markdown","metadata":{"hideCode":false,"hidePrompt":false,"id":"8ONPtf9lECv9"},"source":["# Annotation consistency\n","\n","High quality data is important in machine learning. However, data quality can suffer as a result of manual labelling. Even when annotation guidelines are provided to human labelers, the labels can be inconsistent. One way to evaluate quality of the labels is to evaluate the inter-rater agreement for the human labels. In the exercise you will compute intersection over uninion (IoU) on bounding boxes. IOU is an evaluation metric used to measure the accuracy of an object detector on a particular dataset.  <br>\n","\n","## 1 Draw all boxes from one single annotator onto one image\n","In this first task, you will load an image and draw the bounding boxes provided by one annotator.\n","\n","> **TASK 1.** Write code to load image and plot bounding boxes (annotations) onto the image:\n","\n","> - Load image using Matplotlib library's `imread()` to load image in the form of an array of the pixel and `imshow()` to display the image\n","\n","> - Draw annotations (coordinates of bounding box) onto the image\n","\n","In order to ensure modular code, you will first write functions to (1) load and display image and (2) draw a single bounding box onto image (3) draw more than one bounding box onto an image\n","\n","### Loading image\n","\n","You can load image by using the Matplotlib library, which relies on the Pillow library, to load image data. Pillow is a useful tool for loading and manipulating image. To load an image, simply use the `imread('PATH')` and `imshow()` functions of the matplotlib.image module. The `imread('PATH')` function assigns numpy array to a variable of which can be rendered with `imshow()` function. Python uses image data in form of NumPy array `[Height, Width, Channel]` format. Try printing the numpy array of the image."]},{"cell_type":"code","execution_count":null,"metadata":{"hideCode":false,"hidePrompt":false,"id":"_EWki1J_ECv-"},"outputs":[],"source":["# Task 1 draw all boxes from one single annotator onto an image\n","\n","## Loading image Example\n","\n","PATH = 'C:/Users/jepty/Desktop/SEM study/Year 3/DIT822 - Software engineering for AI system/Labs/Lab10/annotation_consistency/image1_FC_34243.jpg'\n","\n","\n","image = plt.imread(PATH)\n","\n","\n","plt.imshow(image)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"hideCode":false,"hidePrompt":false,"id":"qNqQ7K0cECv-"},"source":["### Drawing annotations (bouding box coordinates) onto image\n","\n","You can draw bounding box using `Rectangle()` from *matplotlib.patches* class. The `Rectangle()` draws a rectangle whose dimensions are specified as its parameters `xy, width, height`. The `xy=(x,y)` parameter specifies the bottom and left rectangle coordinates.\n","\n","If you open annotations in the judgement JSON file, you will notice the following structure:\n","```json\n","\"0\": [\n","    {\n","      \"boundaries\": [\n","        {\n","          \"boundaryPoints\": [\n","            {\n","              \"coords\": [\n","                7.460422039031982,\n","                512.8555297851562\n","              ],\n","              \"edge\": \"Bottom\",\n","              \"visible\": true\n","            },\n","            {\n","              \"coords\": [\n","                0.6261528134346008,\n","                578.7573852539062\n","              ],\n","              \"edge\": \"Left\",\n","              \"visible\": true\n","            },\n","            {\n","              \"coords\": [\n","                51.3950080871582,\n","                667.11474609375\n","              ],\n","              \"edge\": \"Top\",\n","              \"visible\": true\n","            },\n","            {\n","              \"coords\": [\n","                74.82678985595703,\n","                581.6864013671875\n","              ],\n","              \"edge\": \"Right\",\n","              \"visible\": true\n","            }\n","          ],\n","          \"cameraId\": 0\n","        }\n","      ],\n","      \"properties\": {\n","        \"ObjectID\": 1\n","      },\n","      \"selectionMethod\": \"outer_points\",\n","      \"type\": \"Vehicle\"\n","    },\n","    ...\n","    ...\n","```\n","\"0\" denotes annotation entry from an annotator. The annotator has provided a number of bounding boxes (boundaries) whose coordinates are provided within the boundaryPoints. The coordinates are provided for the different edges (Bottom, Left, Top and Right) of the bounding box.  In order to draw the bounding box using `matplotlib.patches.Rectangle((x,  y), width, height)` you need to access the coordinates of each edge and get the correct parameters for the rectangle.\n","\n","Notice that coords are in a list of x,y (e.g., 74.82678985595703, 581.6864013671875). Therefore, you can assign all coords of x in one list and use them to get width by simply subtracting maximum value of x from the smallest value of x. Similarly, assign all y coords in order to compute the height. xy `matplotlib.patches.Rectangle((x,  y), width, height)`  value of the rectangle are the minimum values of x and y.\n","\n","<img src=\"annotation_consistency/box.png\" alt=\"drawing\" width=\"300\"/>\n","\n","\n","#### Expected Answer\n","\n","<img src=\"annotation_consistency/Task1.png\" alt=\"drawing\" width=\"300\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"hideCode":false,"hidePrompt":false,"id":"DTZ9KxYrECwA"},"outputs":[],"source":["# Task 1 draw all boxes from one single annotator onto an image\n","\n","# ======== Your Code ========\n","\n","imgPath = \"C:/Users/jepty/Desktop/SEM study/Year 3/DIT822 - Software engineering for AI system/Labs/Lab10/annotation_consistency/image1_FC_34243.jpg\"\n","jsonPath = \"C:/Users/jepty/Desktop/SEM study/Year 3/DIT822 - Software engineering for AI system/Labs/Lab10/annotation_consistency/image1_FC_34243_judgements.json\"\n","\n","\n","def getSingle (img, annotations, annotatonID):\n","    figure, plot_axis = plt.subplots()\n","    plot_axis.imshow(img)\n","\n","    boxList = annotations.get(str(annotatonID), [])\n","    for boxData in boxList:\n","        boundaries = boxData.get(\"boundaries\", [])\n","        if boundaries:\n","            boundaries = boundaries[0].get(\"boundaryPoints\", [])\n","            if boundaries:\n","                x_coords = [point[\"coords\"][0] for point in boundaries]\n","                y_coords = [point[\"coords\"][1] for point in boundaries]\n","                minX, maxX = min(x_coords), max(x_coords)\n","                minY, maxY = min(y_coords), max(y_coords)\n","                width = maxX - minX\n","                height = maxY - minY\n","                rect = patches.Rectangle((minX, minY), width, height, facecolor='none', linewidth=0.5, edgecolor='red')\n","                plot_axis.add_patch(rect)\n","\n","    plt.show()\n","\n","img = plt.imread(imgPath)\n","f = open(jsonPath)\n","data = json.load(f)\n","f.close()\n","\n","wantedID = 0\n","getSingle(img, data, wantedID)\n","\n","# ======== Your Code ========"]},{"cell_type":"markdown","metadata":{"hideCode":false,"hidePrompt":false,"id":"rnpOK61XECwB"},"source":["## 2 Draw all boxes avalibale for the same image onto the imagee\n","In this second task, you will draw all the bounding boxes provided by all annotators onto the single image.\n","> **TASK 2.** Write code to draw all annotations available for an image. Note, you need to make small modification to above task\n","\n","#### Expected Answer\n","\n","<img src=\"annotation_consistency/Task2.png\" alt=\"drawing\" width=\"300\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"hideCode":false,"hidePrompt":false,"id":"KsLRxlKLECwB"},"outputs":[],"source":["# Task 2 draw all boxes from all annotators onto an image\n","\n","# ======== Your Code ========\n","\n","\n","imgPath = \"C:/Users/jepty/Desktop/SEM study/Year 3/DIT822 - Software engineering for AI system/Labs/Lab10/annotation_consistency/image1_FC_34243.jpg\"\n","jsonPath = \"C:/Users/jepty/Desktop/SEM study/Year 3/DIT822 - Software engineering for AI system/Labs/Lab10/annotation_consistency/image1_FC_34243_judgements.json\"\n","\n","\n","def getAll(img, annotations):\n","    figure, plot_axis = plt.subplots()\n","    plot_axis.imshow(img)\n","\n","    for annotatorID, boxList in annotations.items():\n","        for boxData in boxList:\n","            boundaries = boxData.get(\"boundaries\", [])\n","\n","            for boundary in boundaries:\n","                boundary_points = boundary.get(\"boundaryPoints\", [])\n","                x_coords = [point.get(\"coords\", [])[0] for point in boundary_points]\n","                y_coords = [point.get(\"coords\", [])[1] for point in boundary_points]\n","                minX, maxX = min(x_coords), max(x_coords)\n","                minY, maxY = min(y_coords), max(y_coords)\n","                width = maxX - minX\n","                height = maxY - minY\n","                rect = patches.Rectangle((minX, minY), width, height, facecolor='none', linewidth=0.5, edgecolor='red')\n","                plot_axis.add_patch(rect)\n","\n","    plt.show()\n","\n","img = plt.imread(imgPath)\n","f = open(jsonPath)\n","data = json.load(f)\n","f.close()\n","\n","getAll(img, data)\n","# ======== Your Code ========"]},{"cell_type":"markdown","metadata":{"hideCode":false,"hidePrompt":false,"id":"LqVZDhC7ECwC"},"source":["## 1.3 Pick two annotators and draw their annotations onto an image\n","In this task, you will select two annotators and draw the bounding boxes provided by the two annotators on a single image\n","\n","> **TASK 3.** Write code to draw annotations available from two annotations onto an image.\n","\n","#### Expected Answer\n","\n","<img src=\"annotation_consistency/Task3.png\" alt=\"drawing\" width=\"300\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"hideCode":false,"hidePrompt":false,"id":"ZNGmIvd0ECwC"},"outputs":[],"source":["\n","# Function to draw bounding boxes for specific annotators on the image\n","def draw_boxes(image, annotations, chosen_annotators):\n","    fig, ax = plt.subplots()\n","    ax.imshow(image)\n","\n","    colors = {'0': 'red', '1': 'blue'}  #Colors for different annotators\n","\n","\n","    for annotator_id, bbox_list in annotations.items():\n","        if annotator_id in chosen_annotators:\n","            for bbox_info in bbox_list:\n","                boundaries = bbox_info.get(\"boundaries\", [])\n","\n","\n","                for boundary in boundaries:\n","                    boundary_points = boundary.get(\"boundaryPoints\", [])\n","                    x_coords = [point.get(\"coords\", [])[0] for point in boundary_points]\n","                    y_coords = [point.get(\"coords\", [])[1] for point in boundary_points]\n","                    min_x, max_x = min(x_coords), max(x_coords)\n","                    min_y, max_y = min(y_coords), max(y_coords)\n","                    width = max_x - min_x\n","                    height = max_y - min_y\n","\n","                    #Create a Rectangle patch with the appropriate color\n","                    rect = patches.Rectangle((min_x, min_y), width, height, linewidth=1, edgecolor=colors[annotator_id], facecolor='none')\n","\n","                    #Add the Rectangle to the plot\n","                    ax.add_patch(rect)\n","\n","    plt.show()\n","\n","#Specify the image path and JSON file path\n","image_path = \"/Users/mainashabani/Downloads/Lab10/annotation_consistency/image1_FC_34243.jpg\"\n","json_path = \"/Users/mainashabani/Downloads/Lab10/annotation_consistency/image1_FC_34243_judgements.json\"\n","image = plt.imread(image_path)\n","\n","with open(json_path) as f:\n","    annotation_data = json.load(f)\n","\n","# Specify the annotators to be included\n","chosen_annotators = [\"0\", \"1\"]\n","\n","# Draw the bounding boxes for the specified annotators on the image with different colors\n","draw_boxes(image, annotation_data, chosen_annotators)\n"]},{"cell_type":"markdown","metadata":{"hideCode":false,"hidePrompt":false,"id":"BVXmSvT_ECwD"},"source":["## 4 Compute the IOU between the annotations of the two annotators\n","\n","In this last task, you will compute the IOU from the annotations of the two annotators\n","\n","> **TASK 4.** Write code to compute IOU from two annotators on a single image\n","\n","Task 1.3 should give you the coordinates of the the bounding box. Use the following image to get an idea of how you can compute area of intersection as well as the total area of overlap in order to compute IOU.\n","\n","<img src=\"annotation_consistency/iou.png\" alt=\"drawing\" width=\"600\"/>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"hideCode":false,"hidePrompt":false,"id":"FvmxcclsECwD"},"outputs":[],"source":["def calculate_iou(box1, box2):\n","    #Extract the coordinates of the first bounding box\n","    box1_coords = [point[\"coords\"] for point in box1[\"boundaryPoints\"]]\n","    x1 = min(coord[0] for coord in box1_coords)\n","    y1 = min(coord[1] for coord in box1_coords)\n","    x2 = max(coord[0] for coord in box1_coords)\n","    y2 = max(coord[1] for coord in box1_coords)\n","\n","    #Extract the coordinates of the second bounding box\n","    box2_coords = [point[\"coords\"] for point in box2[\"boundaryPoints\"]]\n","    x1_prime = min(coord[0] for coord in box2_coords)\n","    y1_prime = min(coord[1] for coord in box2_coords)\n","    x2_prime = max(coord[0] for coord in box2_coords)\n","    y2_prime = max(coord[1] for coord in box2_coords)\n","\n","    #Calculate the IoU\n","    intersection_part = max(0, min(x2, x2_prime) - max(x1, x1_prime)) * max(0, min(y2, y2_prime) - max(y1, y1_prime))\n","    area_box1 = (x2 - x1) * (y2 - y1)\n","    area_box2 = (x2_prime - x1_prime) * (y2_prime - y1_prime)\n","    iou = intersection_part / (area_box1 + area_box2 - intersection_part)\n","\n","    return iou\n","\n","#Usage with the two bounding boxes from the data\n","box1 = annotation_data[\"0\"][0][\"boundaries\"][0]\n","box2 = annotation_data[\"1\"][0][\"boundaries\"][0]\n","\n","iou = calculate_iou(box1, box2)\n","print(\"IoU:\", iou)"]}],"metadata":{"celltoolbar":"Edit Metadata","hide_code_all_hidden":false,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}